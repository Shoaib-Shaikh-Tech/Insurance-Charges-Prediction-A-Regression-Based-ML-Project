{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53fe1bef",
   "metadata": {},
   "source": [
    "# Insurance charges — preprocessing, training, and evaluation\n",
    "\n",
    "This notebook loads the provided CSV, performs preprocessing (encoding, dummies, BMI categories),\n",
    "splits into train/test, runs model selection with cross-validation, trains the best model **in memory**\n",
    "(no joblib/pickle files), evaluates it, and writes test predictions merged with X_test to a CSV.\n",
    "You can run this notebook end-to-end. The assistant created this file automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2376242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and load data\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "csv_path = r\"/mnt/data/a282e47b-e0fa-4d76-a0c4-1ae9713b6192.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "print('Loaded CSV shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44de5f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: basic cleaning, encoding, dummies, BMI category\n",
    "df_clean = df.copy()\n",
    "df_clean.drop_duplicates(inplace=True)\n",
    "# Map sex and smoker\n",
    "if 'sex' in df_clean.columns:\n",
    "    df_clean['sex'] = df_clean['sex'].map({'male':0,'female':1})\n",
    "    df_clean.rename(columns={'sex':'is_female'}, inplace=True)\n",
    "if 'smoker' in df_clean.columns:\n",
    "    df_clean['smoker'] = df_clean['smoker'].map({'no':0,'yes':1})\n",
    "    df_clean.rename(columns={'smoker':'is_smoker'}, inplace=True)\n",
    "\n",
    "# Region dummies (drop_first to avoid dummy trap)\n",
    "if 'region' in df_clean.columns:\n",
    "    df_clean = pd.get_dummies(df_clean, columns=['region'], drop_first=True)\n",
    "\n",
    "# BMI category + dummies\n",
    "if 'bmi' in df_clean.columns:\n",
    "    df_clean['bmi_category'] = pd.cut(df_clean['bmi'], bins=[0,18.5,24.9,29.9,float('inf')],\n",
    "                                      labels=['Underweight','Normal','Overweight','Obese'])\n",
    "    df_clean = pd.get_dummies(df_clean, columns=['bmi_category'], drop_first=True)\n",
    "\n",
    "# Show dtypes and first rows\n",
    "print('After preprocessing columns:', df_clean.columns.tolist())\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdb4dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection and train/test split\n",
    "candidate_features = ['age','bmi','children','is_female','is_smoker',\n",
    "                      'region_northwest','region_southeast','region_southwest',\n",
    "                      'bmi_category_Normal','bmi_category_Overweight','bmi_category_Obese']\n",
    "\n",
    "features = [f for f in candidate_features if f in df_clean.columns]\n",
    "print('Using features:', features)\n",
    "\n",
    "X = df_clean[features].copy()\n",
    "y = df_clean['charges'].copy()\n",
    "\n",
    "# Quick check\n",
    "print('X shape, y shape:', X.shape, y.shape)\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print('Train rows:', X_train.shape[0], 'Test rows:', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3c4ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numeric columns (age, bmi, children) using StandardScaler\n",
    "numeric_cols = [c for c in ['age','bmi','children'] if c in X.columns]\n",
    "print('Numeric columns to scale:', numeric_cols)\n",
    "scaler = StandardScaler()\n",
    "if numeric_cols:\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "    X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "else:\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "\n",
    "# Show sample\n",
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ec67fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selection (GridSearchCV) — a compact grid to keep runtime reasonable\n",
    "models = {\n",
    "    'LinearRegression': (LinearRegression(), {}),\n",
    "    'Ridge': (Ridge(), {'alpha':[0.1,1.0,10.0]}),\n",
    "    'Lasso': (Lasso(max_iter=5000), {'alpha':[0.001,0.01,0.1]}),\n",
    "    'RandomForest': (RandomForestRegressor(random_state=42), {'n_estimators':[100,200], 'max_depth':[5,10]}),\n",
    "    'GradientBoosting': (GradientBoostingRegressor(random_state=42), {'n_estimators':[100], 'learning_rate':[0.05,0.1], 'max_depth':[3,5]})\n",
    "}\n",
    "\n",
    "results = {}\n",
    "best_models = {}\n",
    "\n",
    "for name, (model, grid) in models.items():\n",
    "    print('\\nRunning:', name)\n",
    "    if grid:\n",
    "        gs = GridSearchCV(model, grid, scoring='neg_root_mean_squared_error', cv=3, n_jobs=-1)\n",
    "        gs.fit(X_train_scaled, y_train)\n",
    "        best = gs.best_estimator_\n",
    "        cv_rmse = -gs.best_score_\n",
    "        best_params = gs.best_params_\n",
    "    else:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        scores = cross_val_score(model, X_train_scaled, y_train, scoring='neg_root_mean_squared_error', cv=3)\n",
    "        cv_rmse = -scores.mean()\n",
    "        best = model\n",
    "        best_params = {}\n",
    "    preds = best.predict(X_test_scaled)\n",
    "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    results[name] = {'cv_rmse': round(float(cv_rmse),4), 'test_rmse': round(float(rmse),4),\n",
    "                     'test_mae': round(float(mae),4), 'test_r2': round(float(r2),4), 'best_params': best_params}\n",
    "    best_models[name] = best\n",
    "\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results).T.sort_values(by='test_rmse')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eb67f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the best model (selected by test RMSE) and show detailed metrics + feature importances (if available)\n",
    "results_df = results_df  # from previous cell\n",
    "best_name = results_df.index[0]\n",
    "best_model = best_models[best_name]\n",
    "print('Best model selected:', best_name)\n",
    "# Ensure fitted on training set\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "train_preds = best_model.predict(X_train_scaled)\n",
    "test_preds = best_model.predict(X_test_scaled)\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    return {'rmse': mean_squared_error(y_true,y_pred,squared=False),\n",
    "             'mae': mean_absolute_error(y_true,y_pred),\n",
    "             'r2': r2_score(y_true,y_pred)}\n",
    "\n",
    "print('\\nTrain metrics:', metrics(y_train, train_preds))\n",
    "print('Test metrics:', metrics(y_test, test_preds))\n",
    "\n",
    "# If model has feature_importances_ attribute, show it\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    fi = pd.Series(best_model.feature_importances_, index=X_train_scaled.columns).sort_values(ascending=False)\n",
    "    print('\\nFeature importances:\\n', fi)\n",
    "else:\n",
    "    print('\\nModel does not expose feature_importances_.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1846162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save X_test with true and predicted charges to CSV\n",
    "X_test_out = X_test.copy().reset_index(drop=True)\n",
    "X_test_out['true_charges'] = y_test.reset_index(drop=True)\n",
    "X_test_out['pred_charges'] = test_preds\n",
    "X_test_out.to_csv(r\"/mnt/data/test_predictions_final.csv\", index=False)\n",
    "print('Saved test predictions to:', r\"/mnt/data/test_predictions_final.csv\")\n",
    "X_test_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df2c650",
   "metadata": {},
   "source": [
    "## Short conclusions\n",
    "\n",
    "- This notebook selected the best model by test RMSE and reported train/test metrics.\n",
    "- No joblib/pickle files were created; model is trained in memory.\n",
    "- Test predictions CSV was saved as `/mnt/data/test_predictions_final.csv`.\n",
    "\n",
    "Run the notebook cells in order to reproduce results."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
